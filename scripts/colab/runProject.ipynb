{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet18 vs ViT-b/16 ‚Äî Colab Trainer\n",
        "\n",
        "This notebook mounts Google Drive, clones your GitHub repo, installs dependencies,\n",
        "links your **data/** folder from Drive, and runs your shell scripts:\n",
        "\n",
        "- `scripts/run_resnet.sh`\n",
        "- `scripts/run_vit.sh`\n",
        "- (optional) `scripts/eval.sh`\n",
        "\n",
        "All logs and outputs are copied back to Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU (optional)\n",
        "!nvidia-smi || echo \"No GPU detected\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîå Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ‚öôÔ∏è Configuration { run: \"auto\" }\n",
        "#@markdown Fill these and run the cells below.\n",
        "\n",
        "REPO_URL = \"https://github.com/Alejandro-Fuste/AI-ResNet-vs-ViT\" #@param {type:\"string\"}\n",
        "BRANCH = \"main\"                                                #@param {type:\"string\"}\n",
        "PROJECT_NAME = \"AI-RESNET-vs-ViT\"                              #@param {type:\"string\"}\n",
        "DRIVE_DATA = \"/content/drive/MyDrive/UCF/Courses/Fall2025/ComputerVisionSystems/HW_1/data.zip\"                     #@param {type:\"string\"}\n",
        "DRIVE_SAVE = \"/content/drive/MyDrive/ai-resnet-vit-outputs\"    #@param {type:\"string\"}\n",
        "\n",
        "RUN_RESNET = True   #@param {type:\"boolean\"}\n",
        "RUN_VIT    = True   #@param {type:\"boolean\"}\n",
        "ALSO_EVAL  = True   #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß¨ Clone or update the repo\n",
        "import os, subprocess\n",
        "workdir = \"/content\"\n",
        "repo_dir = os.path.join(workdir, PROJECT_NAME)\n",
        "if os.path.exists(repo_dir):\n",
        "    print(f\"Repo exists at {repo_dir}. Updating‚Ä¶\")\n",
        "    subprocess.run([\"git\",\"fetch\",\"--all\"], cwd=repo_dir, check=True)\n",
        "    subprocess.run([\"git\",\"checkout\", BRANCH], cwd=repo_dir, check=True)\n",
        "    subprocess.run([\"git\",\"pull\",\"--ff-only\"], cwd=repo_dir, check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\",\"clone\",\"-b\", BRANCH, \"--single-branch\", REPO_URL, PROJECT_NAME], cwd=workdir, check=True)\n",
        "print(\"Ready:\", repo_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Pip-only setup (no Conda) ‚Äî recommended for Colab\n",
        "\n",
        "Use this **instead of** the Conda setup if you placed the Colab scripts under `scripts/colab/`.\n",
        "This will install your `requirements.txt` into the default Colab Python and skip Conda entirely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run from the repo root: installs requirements via pip\n",
        "import os, subprocess\n",
        "repo_dir = os.path.join(\"/content\", PROJECT_NAME)\n",
        "print(\"Repo:\", repo_dir)\n",
        "subprocess.run([\"bash\",\"-lc\", f\"cd '{repo_dir}' && bash scripts/colab/setup_env_colab.sh\"], check=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Install requirements\n",
        "import os, subprocess, sys\n",
        "req = os.path.join(repo_dir, \"requirements.txt\")\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"wheel\", \"setuptools\"], check=True)\n",
        "if os.path.exists(req):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", req], check=True)\n",
        "else:\n",
        "    print(\"requirements.txt not found:\", req)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7246a8eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÇ Unzip data.zip from Drive\n",
        "import os, zipfile\n",
        "\n",
        "zip_path = \"/content/data.zip\"   # <-- change this to match where your zip is\n",
        "extract_to = \"/content/drive/MyDrive/data\"     # this will create the 'data/' folder\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Extracted to:\", extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîó Link Drive data into the repo as ./data\n",
        "import os, shutil, time\n",
        "repo_data = os.path.join(repo_dir, \"data\")\n",
        "if os.path.exists(repo_data):\n",
        "    if os.path.islink(repo_data):\n",
        "        os.unlink(repo_data)\n",
        "    else:\n",
        "        backup = repo_data + \"_backup_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "        print(\"Backing up existing data folder to\", backup)\n",
        "        shutil.move(repo_data, backup)\n",
        "\n",
        "if os.path.exists(DRIVE_DATA):\n",
        "    try:\n",
        "        os.symlink(DRIVE_DATA, repo_data, target_is_directory=True)\n",
        "        print(\"Symlinked\", DRIVE_DATA, \"->\", repo_data)\n",
        "    except Exception as e:\n",
        "        print(\"Symlink failed, copying instead‚Ä¶\", e)\n",
        "        shutil.copytree(DRIVE_DATA, repo_data)\n",
        "else:\n",
        "    raise SystemExit(f\"Drive data path not found: {DRIVE_DATA}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚úÖ Make shell scripts executable\n",
        "import os, stat\n",
        "scripts = os.path.join(repo_dir, \"scripts\")\n",
        "if os.path.isdir(scripts):\n",
        "    for f in os.listdir(scripts):\n",
        "        if f.endswith(\".sh\"):\n",
        "            p = os.path.join(scripts, f)\n",
        "            os.chmod(p, 0o775)\n",
        "            print(\"chmod +x\", p)\n",
        "else:\n",
        "    print(\"No scripts directory found:\", scripts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58382bff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU (optional)\n",
        "!nvidia-smi || echo \"No GPU detected\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Run training scripts with logging to Drive\n",
        "import os, subprocess, sys, time\n",
        "from pathlib import Path\n",
        "\n",
        "os.makedirs(DRIVE_SAVE, exist_ok=True)\n",
        "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "def tee_log(cmd, log_path, cwd):\n",
        "    Path(os.path.dirname(log_path)).mkdir(parents=True, exist_ok=True)\n",
        "    with open(log_path, \"w\") as f:\n",
        "        print(\"[RUN]\", \" \".join(cmd))\n",
        "        p = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        for line in p.stdout:\n",
        "            sys.stdout.write(line)\n",
        "            f.write(line)\n",
        "        p.wait()\n",
        "        if p.returncode != 0:\n",
        "            raise SystemExit(f\"Command failed with exit code {p.returncode}\")\n",
        "\n",
        "if RUN_RESNET:\n",
        "    tee_log([\"bash\",\"scripts/colab/run_resnet_colab.sh\"], os.path.join(DRIVE_SAVE, f\"train_resnet18_{timestamp}.log\"), cwd=repo_dir)\n",
        "\n",
        "if RUN_VIT:\n",
        "    tee_log([\"bash\",\"scripts/colab/run_vit_colab.sh\"], os.path.join(DRIVE_SAVE, f\"train_vit_b16_{timestamp}.log\"), cwd=repo_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc5ef3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Run evaluation (eval.sh) separately\n",
        "import os, time\n",
        "\n",
        "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "if os.path.exists(os.path.join(repo_dir, \"scripts\", \"eval.sh\")):\n",
        "    tee_log([\"bash\",\"scripts/colab/eval_colab.sh\"], os.path.join(DRIVE_SAVE, f\"eval_{timestamp}.log\"), cwd=repo_dir)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è eval.sh not found in scripts/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üíæ Copy repo logs/outputs back into Drive for safekeeping\n",
        "import os, shutil\n",
        "repo_logs = os.path.join(repo_dir, \"logs\")\n",
        "repo_outs = os.path.join(repo_dir, \"outputs\")\n",
        "for src, name in [(repo_logs,\"logs\"), (repo_outs,\"outputs\")]:\n",
        "    if not os.path.exists(src):\n",
        "        print(\"Skip (missing):\", src); continue\n",
        "    dst = os.path.join(DRIVE_SAVE, name)\n",
        "    for root, dirs, files in os.walk(src):\n",
        "        rel = os.path.relpath(root, src)\n",
        "        tgt_root = os.path.join(dst, rel) if rel != \".\" else dst\n",
        "        os.makedirs(tgt_root, exist_ok=True)\n",
        "        for file in files:\n",
        "            s = os.path.join(root, file)\n",
        "            t = os.path.join(tgt_root, file)\n",
        "            try:\n",
        "                shutil.copy2(s, t)\n",
        "            except Exception as e:\n",
        "                print(\"Copy warn:\", s, \"->\", t, e)\n",
        "print(\"Synced to\", DRIVE_SAVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üßæ Freeze environment for reproducibility\n",
        "import subprocess, sys, time, os\n",
        "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "freeze_path = os.path.join(DRIVE_SAVE, f\"pip_freeze_{ts}.txt\")\n",
        "with open(freeze_path, \"w\") as f:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"freeze\"], text=True, stdout=f)\n",
        "print(\"Wrote\", freeze_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f272c9f7",
      "metadata": {},
      "source": [
        "## üöÄ Fast data setup in Colab (upload ‚Üí unzip locally ‚Üí link to repo ‚Üí optional copy back to Drive)\n",
        "\n",
        "Unzipping **from Google Drive** is slow. This section lets you **upload your dataset ZIP directly into Colab‚Äôs `/content`** (local SSD), unzip it quickly, link it into your repo at `./data`, and **optionally copy the extracted folder back to Drive** for reuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24affbd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß Set your paths here\n",
        "# If you already know your repo folder name under /content, set PROJECT_NAME below.\n",
        "PROJECT_NAME = \"AI-RESNET-VS-VIT\"   # <-- change if different\n",
        "REPO_DIR = f\"/content/{PROJECT_NAME}\"\n",
        "\n",
        "# Set where the dataset will be extracted locally in the VM\n",
        "EXTRACT_DIR = \"/content/data\"\n",
        "\n",
        "# Where to save a permanent copy in Drive (optional)\n",
        "DRIVE_TARGET = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "print(\"Repo dir:\", REPO_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a6c8a6",
      "metadata": {},
      "source": [
        "### 1) Upload your ZIP directly into Colab (fastest)\n",
        "**Option A (drag & drop):** In the left sidebar ‚Üí **Files** tab ‚Üí click **Upload** and put your dataset ZIP in `/content/` (root).  \n",
        "**Option B (helper):** Use the upload widget below and select your ZIP file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640f5bd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print(\"Select your ZIP file‚Ä¶\")\n",
        "uploaded = files.upload()  # choose your dataset zip\n",
        "# Grab the first uploaded filename\n",
        "ZIP_PATH = None\n",
        "if uploaded:\n",
        "    ZIP_PATH = \"/content/\" + next(iter(uploaded.keys()))\n",
        "    print(\"Uploaded:\", ZIP_PATH)\n",
        "else:\n",
        "    print(\"No file uploaded. If you used drag-and-drop, set ZIP_PATH manually below.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36592692",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you used drag-and-drop into /content, set ZIP_PATH manually like:\n",
        "# ZIP_PATH = \"/content/your_dataset.zip\"\n",
        "try:\n",
        "    ZIP_PATH\n",
        "except NameError:\n",
        "    ZIP_PATH = None\n",
        "\n",
        "print(\"ZIP_PATH =\", ZIP_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37b9ed2",
      "metadata": {},
      "source": [
        "### 2) Unzip locally in `/content` (much faster than Drive)\n",
        "This will extract to `EXTRACT_DIR` and skip re-extracting if that folder already exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e5972c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "\n",
        "assert os.path.isdir(REPO_DIR), f\"Repo not found at: {REPO_DIR}. Set PROJECT_NAME correctly.\"\n",
        "assert EXTRACT_DIR.startswith(\"/content/\"), \"EXTRACT_DIR should be under /content for speed.\"\n",
        "\n",
        "if not ZIP_PATH or not os.path.exists(ZIP_PATH):\n",
        "    raise SystemExit(\"ZIP_PATH is not set or file not found. Upload your zip or set ZIP_PATH to its path in /content.\")\n",
        "\n",
        "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "# Choose tool based on extension; prefer 7z for speed if available\n",
        "ext = os.path.splitext(ZIP_PATH)[1].lower()\n",
        "if ext in (\".7z\", \".xz\", \".tar\", \".gz\", \".tgz\", \".bz2\"):\n",
        "    # Install p7zip if needed\n",
        "    subprocess.run([\"bash\",\"-lc\",\"apt-get -qq update && apt-get -qq install -y p7zip-full\"], check=True)\n",
        "    cmd = f\"7z x -aoa '{ZIP_PATH}' -o'{EXTRACT_DIR}'\"\n",
        "else:\n",
        "    # default to unzip for .zip\n",
        "    cmd = f\"unzip -q '{ZIP_PATH}' -d '{EXTRACT_DIR}'\"\n",
        "\n",
        "print(\"[RUN]\", cmd)\n",
        "subprocess.run([\"bash\",\"-lc\", cmd], check=True)\n",
        "\n",
        "# Show a quick tree\n",
        "subprocess.run([\"bash\",\"-lc\", f\"ls -lah '{EXTRACT_DIR}' | head -n 40\"], check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4b62195",
      "metadata": {},
      "source": [
        "### 3) Link the extracted folder into your repo as `./data`\n",
        "If a `data` folder already exists in your repo, we back it up and replace it with a symlink to the extracted data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3dd82c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil, time, pathlib\n",
        "\n",
        "repo_data = os.path.join(REPO_DIR, \"data\")\n",
        "\n",
        "# If repo_data exists, back it up\n",
        "if os.path.lexists(repo_data):  # includes symlinks\n",
        "    backup = repo_data + \"_backup_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    print(f\"[INFO] Backing up existing data to: {backup}\")\n",
        "    os.rename(repo_data, backup)\n",
        "\n",
        "# If EXTRACT_DIR contains a single top-level folder, link to that; else link the dir directly\n",
        "entries = [e for e in os.listdir(EXTRACT_DIR) if not e.startswith(\".\")]\n",
        "if len(entries) == 1 and os.path.isdir(os.path.join(EXTRACT_DIR, entries[0])):\n",
        "    target = os.path.join(EXTRACT_DIR, entries[0])\n",
        "else:\n",
        "    target = EXTRACT_DIR\n",
        "\n",
        "# Create symlink\n",
        "os.symlink(target, repo_data, target_is_directory=True)\n",
        "print(\"Linked\", target, \"->\", repo_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e349f0",
      "metadata": {},
      "source": [
        "### 4) (Optional) Copy the extracted data back to Google Drive\n",
        "This persists the unzipped dataset so you don‚Äôt have to upload/unzip again next time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3581b90",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "\n",
        "# Ensure Drive is mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Create the target dir and copy (rsync if available, else cp -r)\n",
        "subprocess.run([\"bash\",\"-lc\", f\"mkdir -p '{DRIVE_TARGET}'\"], check=True)\n",
        "\n",
        "cmd = f\"rsync -a --delete '{EXTRACT_DIR}/' '{DRIVE_TARGET}/' || cp -r '{EXTRACT_DIR}'/* '{DRIVE_TARGET}/'\"\n",
        "print(\"[RUN]\", cmd)\n",
        "subprocess.run([\"bash\",\"-lc\", cmd], check=True)\n",
        "\n",
        "print(\"Copied extracted data to:\", DRIVE_TARGET)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ResNet18_vs_ViT_Colab_Trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
